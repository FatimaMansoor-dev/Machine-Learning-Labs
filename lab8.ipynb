{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c796ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mglearn.datasets import make_wave\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import mglearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4190a87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance Metrics:\n",
      "\n",
      "|      |   accuracy |   precision |   recall | fpr                                           |   roc_auc |\n",
      "|:-----|-----------:|------------:|---------:|:----------------------------------------------|----------:|\n",
      "| iris |      1     |       1     |    1     | [0.        ,0.52380952,0.52380952,1.        ] |     0.476 |\n",
      "| wine |      0.972 |       0.978 |    0.979 | [0. ,0.3,0.3,1. ]                             |     0.678 |\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Q1) Analyze the performance of decision tree with respect to accuracy, recall, precision, FPR, and ROC\n",
    "   metrics for iris and wine datasets. Hint: the datasets can be loaded using sklearn.datasets.load\n",
    "   function.\n",
    "'''\n",
    "\n",
    "def compute_metrics(loader, random_state):\n",
    "    data = loader()\n",
    "    X, y = data.data, data.target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=random_state\n",
    "    )\n",
    "    # training\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    # metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return accuracy, precision, recall, fpr, roc_auc\n",
    "\n",
    "\n",
    "# Compute metrics for Iris and Wine datasets\n",
    "iris_metrics = compute_metrics(load_iris, random_state=42)\n",
    "wine_metrics = compute_metrics(load_wine, random_state=0)\n",
    "\n",
    "# Aggregate results into DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'accuracy': [iris_metrics[0], wine_metrics[0]],\n",
    "    'precision': [iris_metrics[1], wine_metrics[1]],\n",
    "    'recall': [iris_metrics[2], wine_metrics[2]],\n",
    "    'fpr': [iris_metrics[3], wine_metrics[3]],\n",
    "    'roc_auc': [iris_metrics[4], wine_metrics[4]],\n",
    "}, index=['iris', 'wine'])\n",
    "\n",
    "# Round numeric metrics to 3 decimals for readability\n",
    "df[['accuracy', 'precision', 'recall', 'roc_auc']] = df[['accuracy', 'precision', 'recall', 'roc_auc']].round(3)\n",
    "# Convert FPR arrays to string representation without truncation\n",
    "df['fpr'] = df['fpr'].apply(lambda arr: np.array2string(np.array(arr), separator=','))\n",
    "\n",
    "# Display as a proper markdown table\n",
    "print(\"Decision Tree Performance Metrics:\\n\")\n",
    "print(df.to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a7bfcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train vs. Test Accuracies for Different Depths:\n",
      "\n",
      "| dataset   |   ('train_accuracy', 3) |   ('train_accuracy', 4) |   ('train_accuracy', 5) |   ('train_accuracy', 'unpruned') |   ('test_accuracy', 3) |   ('test_accuracy', 4) |   ('test_accuracy', 5) |   ('test_accuracy', 'unpruned') |\n",
      "|:----------|------------------------:|------------------------:|------------------------:|---------------------------------:|-----------------------:|-----------------------:|-----------------------:|--------------------------------:|\n",
      "| iris      |                   0.958 |                   0.975 |                   0.992 |                                1 |                  1     |                  1     |                  1     |                           1     |\n",
      "| wine      |                   0.993 |                   1     |                   1     |                                1 |                  0.972 |                  0.972 |                  0.972 |                           0.972 |\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Q2) Analyze the impact on accuracy of training and testing for iris and wine datasets due to the unpruned\n",
    "tree and tree depth of 3, 4, and 5.\n",
    "'''\n",
    "\n",
    "def compute_train_test_accuracy(loader, random_state, max_depth=None):\n",
    "    ''' Function to compute training and testing accuracy for a given depth '''\n",
    "    data = loader()\n",
    "    X, y = data.data, data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Train Decision Tree Classifier\n",
    "    model = DecisionTreeClassifier(random_state=0, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "  \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_acc, test_acc\n",
    "\n",
    "# Define depths\n",
    "depths = [None, 3, 4, 5]\n",
    "labels = ['unpruned'] + [str(d) for d in depths if d is not None]\n",
    "\n",
    "# Prepare DataFrame to collect results\n",
    "results = []\n",
    "for name, loader, rs in [('iris', load_iris, 42), ('wine', load_wine, 0)]:\n",
    "    for depth in depths:\n",
    "        train_acc, test_acc = compute_train_test_accuracy(loader, rs, max_depth=depth)\n",
    "        results.append({\n",
    "            'dataset': name,\n",
    "            'max_depth': 'unpruned' if depth is None else depth,\n",
    "            'train_accuracy': round(train_acc, 3),\n",
    "            'test_accuracy': round(test_acc, 3)\n",
    "        })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "# Pivot for readability\n",
    "pivot_df = df.pivot(index='dataset', columns='max_depth', values=['train_accuracy', 'test_accuracy'])\n",
    "\n",
    "# Display overall results\n",
    "print(\"Decision Tree Train vs. Test Accuracies for Different Depths:\\n\")\n",
    "print(pivot_df.to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb11350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Linear vs. Tree Regression (R2 & Mean Relative Error):\n",
      "\n",
      "| Dataset        |   ('R2', 'DecisionTree') |   ('R2', 'LinearRegression') |   ('MeanRelativeError', 'DecisionTree') |   ('MeanRelativeError', 'LinearRegression') |\n",
      "|:---------------|-------------------------:|-----------------------------:|----------------------------------------:|--------------------------------------------:|\n",
      "| boston_housing |                    0.832 |                        0.688 |                             0.131       |                                 0.177       |\n",
      "| ram_prices     |                   -0.074 |                       -0.074 |                             4.62121e+07 |                                 4.62121e+07 |\n",
      "| wave           |                    0.613 |                        0.623 |                             1.097       |                                 0.809       |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mean_relative_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "def load_wave():\n",
    "    # make_wave from mglearn.datasets\n",
    "    X, y = make_wave()\n",
    "    return X.reshape(-1, 1), y\n",
    "\n",
    "\n",
    "def load_ram_prices():\n",
    "    # Load RAM prices CSV from mglearn.datasets.DATA_PATH\n",
    "    ram_prices = pd.read_csv(\n",
    "        os.path.join(mglearn.datasets.DATA_PATH, \"ram_price.csv\")\n",
    "    )\n",
    "    # Convert date to ordinal number for regression\n",
    "    ram_prices['date'] = pd.to_datetime(ram_prices['date'])\n",
    "    X = ram_prices['date'].map(pd.Timestamp.toordinal).values.reshape(-1, 1)\n",
    "    y = ram_prices['price'].values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_boston():\n",
    "    # fetch_openml from sklearn.datasets\n",
    "    boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
    "    X = boston.data.values\n",
    "    y = boston.target.astype(float).values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    'wave': load_wave,\n",
    "    'ram_prices': load_ram_prices,\n",
    "    'boston_housing': load_boston\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for name, loader in datasets.items():\n",
    "    \n",
    "    X, y = loader()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=0\n",
    "    )\n",
    "    \n",
    "    # Linear Regression\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(X_train, y_train)\n",
    "    y_lin = lin.predict(X_test)\n",
    "    r2_lin = r2_score(y_test, y_lin)\n",
    "    mre_lin = mean_relative_error(y_test, y_lin)\n",
    "\n",
    "    # Decision Tree Regression\n",
    "    tree = DecisionTreeRegressor(random_state=0)\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_tree = tree.predict(X_test)\n",
    "    r2_tree = r2_score(y_test, y_tree)\n",
    "    mre_tree = mean_relative_error(y_test, y_tree)\n",
    "\n",
    "    # Append to results\n",
    "    results.append((name, 'LinearRegression', round(r2_lin, 3), round(mre_lin, 3)))\n",
    "    results.append((name, 'DecisionTree',    round(r2_tree, 3), round(mre_tree, 3)))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results, columns=['Dataset', 'Model', 'R2', 'MeanRelativeError'])\n",
    "pivot_df = df.pivot(index='Dataset', columns='Model', values=['R2', 'MeanRelativeError'])\n",
    "print(\"Comparison of Linear vs. Tree Regression (R2 & Mean Relative Error):\\n\")\n",
    "print(pivot_df.to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33feced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
