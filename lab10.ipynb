{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a48baae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import mglearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4dbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Desktop\\ml\\Machine-Learning-Labs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\Desktop\\ml\\Machine-Learning-Labs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\Desktop\\ml\\Machine-Learning-Labs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (macro)</th>\n",
       "      <th>Recall (macro)</th>\n",
       "      <th>FPR (macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris</td>\n",
       "      <td>voting_hard</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris</td>\n",
       "      <td>voting_soft</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>rf</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine</td>\n",
       "      <td>voting_hard</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wine</td>\n",
       "      <td>voting_soft</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset   Classifier  Accuracy  Precision (macro)  Recall (macro)  \\\n",
       "0    Iris           rf    0.8889             0.8981             1.0   \n",
       "1    Iris          svm    0.9556             0.9556             1.0   \n",
       "2    Iris           lr    0.9333             0.9345             1.0   \n",
       "3    Iris  voting_hard    0.9333             0.9345             1.0   \n",
       "4    Iris  voting_soft    0.9333             0.9345             1.0   \n",
       "5    Wine           rf    1.0000             1.0000             1.0   \n",
       "6    Wine          svm    0.6667             0.4833             1.0   \n",
       "7    Wine           lr    0.9815             0.9848             1.0   \n",
       "8    Wine  voting_hard    0.9815             0.9848             1.0   \n",
       "9    Wine  voting_soft    0.9815             0.9848             1.0   \n",
       "\n",
       "   FPR (macro)  \n",
       "0       0.0556  \n",
       "1       0.0222  \n",
       "2       0.0333  \n",
       "3       0.0333  \n",
       "4       0.0333  \n",
       "5       0.0000  \n",
       "6       0.1801  \n",
       "7       0.0101  \n",
       "8       0.0101  \n",
       "9       0.0101  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Q1) Compare the performance of random forest, SVM, logistic regression, and voting (hard & soft)\n",
    "classifiers with respect to accuracy, recall, precision, FPR, and ROC metrics for iris and wine\n",
    "datasets. Hint: the datasets can be loaded using sklearn.datasets.load function.\n",
    "'''\n",
    "\n",
    "def compute_fpr(cm):\n",
    "    '''false positive rate per class and return their average'''\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)\n",
    "    tn = cm.sum() - (cm.sum(axis=1) + cm.sum(axis=0) - np.diag(cm))\n",
    "    fpr = fp / (fp + tn)\n",
    "    return np.mean(fpr)\n",
    "\n",
    "results = []\n",
    "\n",
    "classifiers = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('svm', SVC(kernel='rbf', probability=True, random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "]\n",
    "voting_hard = VotingClassifier(classifiers, voting='hard')\n",
    "voting_soft = VotingClassifier(classifiers, voting='soft')\n",
    "all_classifiers = classifiers + [\n",
    "    ('voting_hard', voting_hard),\n",
    "    ('voting_soft', voting_soft),\n",
    "]\n",
    "\n",
    "# Evaluate on both Iris and Wine datasets\n",
    "for name, dataset in [(\"Iris\", datasets.load_iris()), (\"Wine\", datasets.load_wine())]:\n",
    "    X, y = dataset.data, dataset.target\n",
    "    y_bin = label_binarize(y, classes=np.unique(y))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "\n",
    "    for clf_name, clf in all_classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        fpr = compute_fpr(cm)\n",
    "\n",
    "        results.append({\n",
    "            'Dataset': name,\n",
    "            'Classifier': clf_name,\n",
    "            'Accuracy': round(acc, 4),\n",
    "            'Precision (macro)': round(prec, 4),\n",
    "            'Recall (macro)': round(rec, 0),\n",
    "            'FPR (macro)': round(fpr, 4),\n",
    "        })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cc8b392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>n_trees</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>0.981481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>0.981481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wine</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  n_trees  Train Accuracy  Test Accuracy\n",
       "0    Iris       10        0.991935       0.981481\n",
       "1    Iris       50        1.000000       1.000000\n",
       "2    Iris      100        1.000000       1.000000\n",
       "3    Wine       10        0.991935       0.981481\n",
       "4    Wine       50        1.000000       1.000000\n",
       "5    Wine      100        1.000000       1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "2) Analyze the impact on accuracy of training and testing for iris and wine datasets by keeping an\n",
    "ensemble of 10, 50, and 100 decision trees in bagging classifier.\n",
    "'''\n",
    "\n",
    "ensemb = [10, 50, 100]\n",
    "results = []\n",
    "\n",
    "for name, loader in [(\"Iris\", datasets.load_iris()), (\"Wine\", datasets.load_wine())]:\n",
    "    X, y = dataset.data, dataset.target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    for n in ensemb:\n",
    "        bag = BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(random_state=42),\n",
    "            n_estimators=n,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        bag.fit(X_train, y_train)\n",
    "        train_acc = accuracy_score(y_train, bag.predict(X_train))\n",
    "        test_acc  = accuracy_score(y_test,  bag.predict(X_test))\n",
    "        \n",
    "        results.append({\n",
    "            \"Dataset\": name,\n",
    "            \"n_trees\": n,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb4908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>mean_rel_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wave</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.623021</td>\n",
       "      <td>0.809431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wave</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.690468</td>\n",
       "      <td>0.869110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ram_prices</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-0.008742</td>\n",
       "      <td>363.349768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ram_prices</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-0.011309</td>\n",
       "      <td>346.528298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boston_housing</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.744852</td>\n",
       "      <td>0.148574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boston_housing</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.845858</td>\n",
       "      <td>0.111571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset             model        r2  mean_rel_error\n",
       "0            wave  LinearRegression  0.623021        0.809431\n",
       "1            wave      RandomForest  0.690468        0.869110\n",
       "2      ram_prices  LinearRegression -0.008742      363.349768\n",
       "3      ram_prices      RandomForest -0.011309      346.528298\n",
       "4  boston_housing  LinearRegression  0.744852        0.148574\n",
       "5  boston_housing      RandomForest  0.845858        0.111571"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q5) Compare the linear and random forest regressions on the basis of R\n",
    "2\n",
    "and mean relative error for\n",
    "wave, RAM prices, and Boston Housing datasets. Use train-test split of 60:40. Apply the log\n",
    "transformation to preprocess the data.\n",
    "'''\n",
    "def mean_relative_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def load_wave():\n",
    "    X, y = mglearn.datasets.make_wave()\n",
    "    return X.reshape(-1, 1), y\n",
    "\n",
    "\n",
    "def load_ram_prices():\n",
    "    ram = pd.read_csv(\n",
    "        os.path.join(mglearn.datasets.DATA_PATH, \"ram_price.csv\")\n",
    "    )\n",
    "    ram['date'] = pd.to_datetime(ram['date'])\n",
    "    X = ram['date'].map(pd.Timestamp.toordinal).values.reshape(-1, 1)\n",
    "    y = ram['price'].values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_boston():\n",
    "    boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
    "    X = boston.data.values\n",
    "    y = boston.target.astype(float).values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    'wave': load_wave,\n",
    "    'ram_prices': load_ram_prices,\n",
    "    'boston_housing': load_boston\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, loader in datasets.items():\n",
    "    X, y = loader()\n",
    "\n",
    "    # y for wave, rest log trans\n",
    "    if name == 'wave':\n",
    "        y_trans = y\n",
    "        invert = lambda z: z\n",
    "    else:\n",
    "        y_trans = np.log1p(y)\n",
    "        invert = np.expm1    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_trans, test_size=0.4, random_state=0\n",
    "    )\n",
    "\n",
    "    for model_name, model in [\n",
    "        ('LinearRegression', LinearRegression()),\n",
    "        ('RandomForest', RandomForestRegressor(random_state=0))\n",
    "    ]:\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        y_test_orig = invert(y_test)\n",
    "        y_pred_orig = invert(y_pred)\n",
    "        mre = mean_relative_error(y_test_orig, y_pred_orig)\n",
    "\n",
    "        results.append({\n",
    "            'dataset': name,\n",
    "            'model': model_name,\n",
    "            'r2': r2,\n",
    "            'mean_rel_error': mre\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9490cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>fpr_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950710</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950710</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wine</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.014696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.912361</td>\n",
       "      <td>0.889292</td>\n",
       "      <td>0.051993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wine</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.894824</td>\n",
       "      <td>0.847626</td>\n",
       "      <td>0.075904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset        classifier  accuracy  precision_macro  recall_macro  \\\n",
       "0    iris      RandomForest  0.950000         0.950710      0.950000   \n",
       "1    iris          AdaBoost  0.950000         0.950710      0.950000   \n",
       "2    iris  GradientBoosting  0.966667         0.966667      0.966667   \n",
       "3    wine      RandomForest  0.972222         0.974617      0.974617   \n",
       "4    wine          AdaBoost  0.902778         0.912361      0.889292   \n",
       "5    wine  GradientBoosting  0.861111         0.894824      0.847626   \n",
       "\n",
       "   fpr_macro  \n",
       "0   0.025000  \n",
       "1   0.025000  \n",
       "2   0.016667  \n",
       "3   0.014696  \n",
       "4   0.051993  \n",
       "5   0.075904  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Q6) Compare the performance of random forest, adaboost, and gradient boosting classifiers with\n",
    "respect to accuracy, recall, precision, FPR, and ROC metrics for iris and wine datasets.\n",
    "'''\n",
    "\n",
    "def compute_fpr(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)\n",
    "    tn = cm.sum() - (cm.sum(axis=1) + cm.sum(axis=0) - np.diag(cm))\n",
    "    fpr = fp / (fp + tn)\n",
    "    return np.mean(fpr)\n",
    "\n",
    "datasets = {\n",
    "    'iris': load_iris,\n",
    "    'wine': load_wine\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=0),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=0),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for ds_name, loader in datasets.items():\n",
    "    data = loader()\n",
    "    X, y = data.data, data.target\n",
    "    labels = np.unique(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=0, stratify=y\n",
    "    )\n",
    "    \n",
    "    y_test_onehot = pd.get_dummies(y_test).values\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        acc   = accuracy_score(y_test, y_pred)\n",
    "        prec  = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        rec   = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        fpr   = compute_fpr(y_test, y_pred, labels)\n",
    "        \n",
    "        results.append({\n",
    "            'dataset': ds_name,\n",
    "            'classifier': clf_name,\n",
    "            'accuracy': acc,\n",
    "            'precision_macro': prec,\n",
    "            'recall_macro': rec,\n",
    "            'fpr_macro': fpr,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8094d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
